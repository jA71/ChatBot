{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TdcM8JstZWyr",
        "outputId": "df8678c2-393e-40b9-dde9-f7be6857fa3d"
      },
      "outputs": [],
      "source": [
        "# SE INSTALA LOS ELEMENTOS NECESARIOS PARA EL CHATBOT\n",
        "\n",
        "!pip install transformers #wav2vec2 y blenderbot\n",
        "!pip install git+git://github.com/ricardodeazambuja/colab_utils.git #mic\n",
        "!pip install librosa # pre-procesamiento audio\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "odgHMDnCaH-d",
        "outputId": "567da835-606d-4d60-e6d1-678629872969"
      },
      "outputs": [],
      "source": [
        "# Importar librerías\n",
        "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
        "import torch\n",
        "from colab_utils import getAudio\n",
        "import librosa\n",
        "import numpy as np\n",
        "\n",
        "w2v2 = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
        "w2v2_processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base-960h\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H628PDKwbGZH"
      },
      "outputs": [],
      "source": [
        "# Capturar audio del mic (a 48 KHz)\n",
        "audio, sr = getAudio()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P9iaDGzAbJi-"
      },
      "outputs": [],
      "source": [
        "# Cambiar tasa de muestreo a 16 KHz (requerido por wav2vec2)\n",
        "audio_float = audio.astype(np.float32)\n",
        "audio_16k = librosa.resample(audio_float, sr, 16000)\n",
        "print(f'Tamaño audio original: {audio_16k.shape}')\n",
        "\n",
        "# Voz a texto\n",
        "entrada = w2v2_processor(audio_16k, sampling_rate=16000, return_tensors=\"pt\").input_values\n",
        "print(f'Tamaño entrada a wav2vec2: {entrada.shape}')\n",
        "probabilidades = w2v2(entrada).logits\n",
        "print(f'Tamaño arreglo probabilidades (salida de wav2vec2): {probabilidades.shape}')\n",
        "predicciones = torch.argmax(probabilidades, dim=-1)\n",
        "print(f'Tamaño arreglo predicciones: {predicciones.shape}')\n",
        "transcripcion = w2v2_processor.decode(predicciones[0])\n",
        "print(transcripcion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ay2lLehEbMRt"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"facebook/blenderbot-400M-distill\")\n",
        "blender = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/blenderbot-400M-distill\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BrxsTyJbbQPx"
      },
      "outputs": [],
      "source": [
        "blender.generate?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sH4MU7hGbSfR"
      },
      "outputs": [],
      "source": [
        "# Prueba inicial\n",
        "entradaBlender = tokenizer([transcripcion], return_tensors='pt')\n",
        "print(f'Frase de entrada: {transcripcion}')\n",
        "print(f'Entrada a BlenderBot: {entradaBlender}')\n",
        "ids_respuesta = blender.generate(**entradaBlender)\n",
        "print(f'Salida BlenderBot: {ids_respuesta}')\n",
        "respuesta = tokenizer.batch_decode(ids_respuesta)\n",
        "print(f'Salida después del Tokenizer: {respuesta}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MvDtw69CbUwo"
      },
      "outputs": [],
      "source": [
        "# Eliminar tokens de inicio y finalización de frase\n",
        "respuesta = respuesta[0].replace('<s>','').replace('</s>','')\n",
        "print(f'Salida en el formato correcto: {respuesta}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GMtkZVOTbXDr"
      },
      "outputs": [],
      "source": [
        "# Crear un corto chat de prueba\n",
        "NFRASES = 5\n",
        "nfrase = 1\n",
        "while nfrase <= NFRASES:\n",
        "  frase = input('-> MIGUEL: ')\n",
        "  entradaBlender = tokenizer([frase], return_tensors='pt')\n",
        "  ids_respuesta = blender.generate(**entradaBlender)\n",
        "  respuesta = tokenizer.batch_decode(ids_respuesta)\n",
        "  respuesta = respuesta[0].replace('<s>','').replace('</s>','')\n",
        "  print(f'-> BLENDERBOT: {respuesta}')\n",
        "\n",
        "  nfrase += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oYlzmJ_4bZEv"
      },
      "outputs": [],
      "source": [
        "NFRASES = 5\n",
        "nfrase = 1\n",
        "\n",
        "while nfrase <= NFRASES:\n",
        "  input()     # Esperar a pulsar tecla para iniciar grabación\n",
        "  \n",
        "  # Capturar audio y llevarlo a 16 KHz\n",
        "  audio, sr = getAudio()\n",
        "  audio_float = audio.astype(np.float32)\n",
        "  audio_16k = librosa.resample(audio_float, sr, 16000)\n",
        "\n",
        "  # Voz a texto\n",
        "  entrada = w2v2_processor(audio_16k, sampling_rate=16000, return_tensors=\"pt\").input_values\n",
        "  probabilidades = w2v2(entrada).logits\n",
        "  predicciones = torch.argmax(probabilidades, dim=-1)\n",
        "  frase = w2v2_processor.decode(predicciones[0])\n",
        "  \n",
        "  # Imprimir transcripción\n",
        "  print(f'-> MIGUEL: {frase}')\n",
        "\n",
        "  # BlenderBot\n",
        "  entradaBlender = tokenizer([frase], return_tensors='pt')\n",
        "  ids_respuesta = blender.generate(**entradaBlender)\n",
        "  respuesta = tokenizer.batch_decode(ids_respuesta)\n",
        "  respuesta = respuesta[0].replace('<s>','').replace('</s>','')\n",
        "  print(f'-> BLENDERBOT: {respuesta}')\n",
        "\n",
        "  nfrase += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OSy8KtV6bbl_"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Chatbot",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
